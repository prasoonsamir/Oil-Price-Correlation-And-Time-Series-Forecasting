import scipy
import statsmodels.api as sm
from statsmodels.tools.tools import add_constant
from scipy import stats
from scipy.stats import shapiro
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
import keras
import statsmodels
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers import *
from keras.preprocessing.sequence import TimeseriesGenerator
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn import linear_model
from statsmodels.tsa.stattools import adfuller
warnings.filterwarnings("ignore")
df = pd.read_csv("C:\\Users\\Samir Prasun\\Desktop\\production forecasting\\Oil price estimation\\Oil_price.csv")

Y = df.WTI_price.values

result = adfuller(Y)
print('ADF Statistic: %f' % result[0])
print('p-value: %f' % result[1])

stat, p = shapiro(Y)
print('Statistics=%.3f, p=%.3f' % (stat, p))
# interpret
alpha = 0.05
if p > alpha:
	print('Sample looks Gaussian (fail to reject H0)')
else:
	print('Sample does not look Gaussian (reject H0)')
    
x = df.drop(['WTI_price', 'Date', 'Monthly_Consumption_Mbbl', 'Monthly_Production_Mbbl' ], axis=1)
##x = add_constant(df.X)
vif = pd.DataFrame()
vif = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]

print(vif)

##regr = linear_model.LinearRegression()
##regr.fit(df.X, Y)
X = sm.add_constant(x) # adding a constant
 
model = sm.OLS(Y, X).fit()
predictions = model.predict(X) 
 
model.summary()

##z = np.abs(stats.zscore(df.drop(columns=['Date'])))
##print(np.where(z > 3))
##df_data = df[(z > 3).all(axis=1)]

Y = Y.astype('float32')
Y = np.reshape(Y, (-1, 1))
scaler = MinMaxScaler(feature_range = (0, 1))

dataset = scaler.fit_transform(Y)
df.head()
train_size = int(len(dataset) * 0.8)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]

test_actual = scaler.inverse_transform(test)



def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)
    
look_back = 2
train_p, Y_train = create_dataset(train, look_back)
test_p, Y_test = create_dataset(test, look_back)

# reshape input to be [samples, time steps, features]
train_p = np.reshape(train_p, (train_p.shape[0], 1, train_p.shape[1]))
test_p = np.reshape(test_p, (test_p.shape[0], 1, test_p.shape[1]))

lstm_model = Sequential()
lstm_model.add(LSTM(200, input_shape=(train_p.shape[1], train_p.shape[2])))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(1))
lstm_model.compile(loss='mean_squared_error', optimizer='adam')

history = lstm_model.fit(train_p, Y_train, epochs=50, batch_size=40, validation_data=(test_p, Y_test))

train_predict = lstm_model.predict(train_p)
test_predict = lstm_model.predict(test_p)
test_predict_new = scaler.inverse_transform(test_predict)

train_predict_new = scaler.inverse_transform(train_predict)

plt.figure(figsize=(10,6))
plt.plot(Y, color='blue', label='Actual')
plt.plot(train_predict_new , color='red', label='Predicted data')
plt.title('Oil Rate Training')
plt.xlabel('Date')
plt.ylabel('Oil_production_rate')
plt.legend()
plt.show()

plt.figure(figsize=(10,6))
plt.plot(test_actual, color='blue', label='Actual')
plt.plot(test_predict_new , color='red', label='Predicted data')
plt.title('Oil Rate Training')
plt.xlabel('Date')
plt.ylabel('Oil_production_rate')
plt.legend()
plt.show()
